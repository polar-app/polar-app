import React from 'react';

export const Content = () => {
    return (
        <div id='content'>

            Lorem-ipsum-dolor-sit-amet-pro-tota-repudiandae-theophrastus-at-equidem-nostrum-voluptaria-id-mei-Ad-rebum-alienum-consequat-his-Ei-usu-magna-phaedrum-Eu-legimus-detracto-eos-Ea-his-mutat-atqui-viris-sed-facete-prompta-ut-et-nam-integre-malorum-diceret-Pro-ea-unum-malis-omnes-soluta-vocent-euismod-mel-cu-Eu-duo-nihil-quodsi-Quo-albucius-sententiae-contentiones-ei-movet-vituperatoribus-qui-at-in-quo-idque-erant

            <p>
                <b>this</b> and <i>that</i>
            </p>

            <p>this</p>

            {/*<div style={{overflow: "auto", height: '150px'}}>*/}
            {/*    HERE*/}

            {/*    Graph-based neural network models are producing strong results in a*/}
            {/*    number of domains, in part because graphs provide flexibility to*/}
            {/*    encode domain knowledge in the form of relational structure (edges)*/}
            {/*    between nodes in the graph. In practice, edges are used both to*/}
            {/*    represent intrinsic structure (e.g., abstract syntax trees of*/}
            {/*    programs) and more abstract relations that aid reasoning for a*/}
            {/*    downstream task (e.g., results of relevant program analyses). In*/}
            {/*    this work, we study the problem of learning to derive abstract*/}
            {/*    relations from the intrinsic graph structure. Motivated by their*/}
            {/*    power in program analyses, we consider relations defined by paths on*/}
            {/*    the base graph accepted by a finite-state automaton. We show how to*/}
            {/*    learn these relations end-to-end by relaxing the problem into*/}
            {/*    learning finite-state automata policies on a graph-based POMDP and*/}
            {/*    then training these policies using implicit differentiation. The*/}
            {/*    result is a differentiable Graph Finite-State Automaton (GFSA) layer*/}
            {/*    that adds a new edge type (expressed as a weighted adjacency matrix)*/}
            {/*    to a base graph. We demonstrate that this layer can find shortcuts*/}
            {/*    in grid-world graphs and reproduce simple static analyses on Python*/}
            {/*    programs. Additionally, we combine the GFSA layer with a larger*/}
            {/*    graph-based model trained end-to-end on the variable misuse program*/}
            {/*    understanding task, and find that using the GFSA layer leads to*/}
            {/*    better performance than using hand-engineered semantic edges or*/}
            {/*    other baseline methods for adding learned edge types.*/}
            {/*</div>*/}

            Graph-based neural network models are producing strong results in a
            number of domains, in part because graphs provide flexibility to
            encode domain knowledge in the form of relational structure (edges)
            between nodes in the graph. In practice, edges are used both to
            represent intrinsic structure (e.g., abstract syntax trees of
            programs) and more abstract relations that aid reasoning for a
            downstream task (e.g., results of relevant program analyses). In
            this work, we study the problem of learning to derive abstract
            relations from the intrinsic graph structure. Motivated by their
            power in program analyses, we consider relations defined by paths on
            the base graph accepted by a finite-state automaton. We show how to
            learn these relations end-to-end by relaxing the problem into
            learning finite-state automata policies on a graph-based POMDP and
            then training these policies using implicit differentiation. The
            result is a differentiable Graph Finite-State Automaton (GFSA) layer
            that adds a new edge type (expressed as a weighted adjacency matrix)
            to a base graph. We demonstrate that this layer can find shortcuts
            in grid-world graphs and reproduce simple static analyses on Python
            programs. Additionally, we combine the GFSA layer with a larger
            graph-based model trained end-to-end on the variable misuse program
            understanding task, and find that using the GFSA layer leads to
            better performance than using hand-engineered semantic edges or
            other baseline methods for adding learned edge types.

                Graph-based neural network models are producing strong results in a
                number of domains, in part because graphs provide flexibility to
                encode domain knowledge in the form of relational structure (edges)
                between nodes in the graph. In practice, edges are used both to
                represent intrinsic structure (e.g., abstract syntax trees of
                programs) and more abstract relations that aid reasoning for a
                downstream task (e.g., results of relevant program analyses). In
                this work, we study the problem of learning to derive abstract
                relations from the intrinsic graph structure. Motivated by their
                power in program analyses, we consider relations defined by paths on
                the base graph accepted by a finite-state automaton. We show how to
                learn these relations end-to-end by relaxing the problem into
                learning finite-state automata policies on a graph-based POMDP and
                then training these policies using implicit differentiation. The
                result is a differentiable Graph Finite-State Automaton (GFSA) layer
                that adds a new edge type (expressed as a weighted adjacency matrix)
                to a base graph. We demonstrate that this layer can find shortcuts
                in grid-world graphs and reproduce simple static analyses on Python
                programs. Additionally, we combine the GFSA layer with a larger
                graph-based model trained end-to-end on the variable misuse program
                understanding task, and find that using the GFSA layer leads to
                better performance than using hand-engineered semantic edges or
                other baseline methods for adding learned edge types.

                Graph-based neural network models are producing strong results in a
                number of domains, in part because graphs provide flexibility to
                encode domain knowledge in the form of relational structure (edges)
                between nodes in the graph. In practice, edges are used both to
                represent intrinsic structure (e.g., abstract syntax trees of
                programs) and more abstract relations that aid reasoning for a
                downstream task (e.g., results of relevant program analyses). In
                this work, we study the problem of learning to derive abstract
                relations from the intrinsic graph structure. Motivated by their
                power in program analyses, we consider relations defined by paths on
                the base graph accepted by a finite-state automaton. We show how to
                learn these relations end-to-end by relaxing the problem into
                learning finite-state automata policies on a graph-based POMDP and
                then training these policies using implicit differentiation. The
                result is a differentiable Graph Finite-State Automaton (GFSA) layer
                that adds a new edge type (expressed as a weighted adjacency matrix)
                to a base graph. We demonstrate that this layer can find shortcuts
                in grid-world graphs and reproduce simple static analyses on Python
                programs. Additionally, we combine the GFSA layer with a larger
                graph-based model trained end-to-end on the variable misuse program
                understanding task, and find that using the GFSA layer leads to
                better performance than using hand-engineered semantic edges or
                other baseline methods for adding learned edge types.

                Graph-based neural network models are producing strong results in a
                number of domains, in part because graphs provide flexibility to
                encode domain knowledge in the form of relational structure (edges)
                between nodes in the graph. In practice, edges are used both to
                represent intrinsic structure (e.g., abstract syntax trees of
                programs) and more abstract relations that aid reasoning for a
                downstream task (e.g., results of relevant program analyses). In
                this work, we study the problem of learning to derive abstract
                relations from the intrinsic graph structure. Motivated by their
                power in program analyses, we consider relations defined by paths on
                the base graph accepted by a finite-state automaton. We show how to
                learn these relations end-to-end by relaxing the problem into
                learning finite-state automata policies on a graph-based POMDP and
                then training these policies using implicit differentiation. The
                result is a differentiable Graph Finite-State Automaton (GFSA) layer
                that adds a new edge type (expressed as a weighted adjacency matrix)
                to a base graph. We demonstrate that this layer can find shortcuts
                in grid-world graphs and reproduce simple static analyses on Python
                programs. Additionally, we combine the GFSA layer with a larger
                graph-based model trained end-to-end on the variable misuse program
                understanding task, and find that using the GFSA layer leads to
                better performance than using hand-engineered semantic edges or
                other baseline methods for adding learned edge types.

                Graph-based neural network models are producing strong results in a
                number of domains, in part because graphs provide flexibility to
                encode domain knowledge in the form of relational structure (edges)
                between nodes in the graph. In practice, edges are used both to
                represent intrinsic structure (e.g., abstract syntax trees of
                programs) and more abstract relations that aid reasoning for a
                downstream task (e.g., results of relevant program analyses). In
                this work, we study the problem of learning to derive abstract
                relations from the intrinsic graph structure. Motivated by their
                power in program analyses, we consider relations defined by paths on
                the base graph accepted by a finite-state automaton. We show how to
                learn these relations end-to-end by relaxing the problem into
                learning finite-state automata policies on a graph-based POMDP and
                then training these policies using implicit differentiation. The
                result is a differentiable Graph Finite-State Automaton (GFSA) layer
                that adds a new edge type (expressed as a weighted adjacency matrix)
                to a base graph. We demonstrate that this layer can find shortcuts
                in grid-world graphs and reproduce simple static analyses on Python
                programs. Additionally, we combine the GFSA layer with a larger
                graph-based model trained end-to-end on the variable misuse program
                understanding task, and find that using the GFSA layer leads to
                better performance than using hand-engineered semantic edges or
                other baseline methods for adding learned edge types.

                Graph-based neural network models are producing strong results in a
                number of domains, in part because graphs provide flexibility to
                encode domain knowledge in the form of relational structure (edges)
                between nodes in the graph. In practice, edges are used both to
                represent intrinsic structure (e.g., abstract syntax trees of
                programs) and more abstract relations that aid reasoning for a
                downstream task (e.g., results of relevant program analyses). In
                this work, we study the problem of learning to derive abstract
                relations from the intrinsic graph structure. Motivated by their
                power in program analyses, we consider relations defined by paths on
                the base graph accepted by a finite-state automaton. We show how to
                learn these relations end-to-end by relaxing the problem into
                learning finite-state automata policies on a graph-based POMDP and
                then training these policies using implicit differentiation. The
                result is a differentiable Graph Finite-State Automaton (GFSA) layer
                that adds a new edge type (expressed as a weighted adjacency matrix)
                to a base graph. We demonstrate that this layer can find shortcuts
                in grid-world graphs and reproduce simple static analyses on Python
                programs. Additionally, we combine the GFSA layer with a larger
                graph-based model trained end-to-end on the variable misuse program
                understanding task, and find that using the GFSA layer leads to
                better performance than using hand-engineered semantic edges or
                other baseline methods for adding learned edge types.

                Graph-based neural network models are producing strong results in a
                number of domains, in part because graphs provide flexibility to
                encode domain knowledge in the form of relational structure (edges)
                between nodes in the graph. In practice, edges are used both to
                represent intrinsic structure (e.g., abstract syntax trees of
                programs) and more abstract relations that aid reasoning for a
                downstream task (e.g., results of relevant program analyses). In
                this work, we study the problem of learning to derive abstract
                relations from the intrinsic graph structure. Motivated by their
                power in program analyses, we consider relations defined by paths on
                the base graph accepted by a finite-state automaton. We show how to
                learn these relations end-to-end by relaxing the problem into
                learning finite-state automata policies on a graph-based POMDP and
                then training these policies using implicit differentiation. The
                result is a differentiable Graph Finite-State Automaton (GFSA) layer
                that adds a new edge type (expressed as a weighted adjacency matrix)
                to a base graph. We demonstrate that this layer can find shortcuts
                in grid-world graphs and reproduce simple static analyses on Python
                programs. Additionally, we combine the GFSA layer with a larger
                graph-based model trained end-to-end on the variable misuse program
                understanding task, and find that using the GFSA layer leads to
                better performance than using hand-engineered semantic edges or
                other baseline methods for adding learned edge types.



            <p>
                this is a test
            </p>

            <p>
                This is some more text
            </p>

            <p>
                this is a test
            </p>

        </div>
    );
}
